{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8e886c8c",
   "metadata": {},
   "source": [
    "# Yeu cau 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ae7a387f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 23:41:47.054807: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-09-30 23:41:47.420700: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1759250507.543965   63138 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1759250507.578516   63138 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "W0000 00:00:1759250507.855648   63138 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759250507.855684   63138 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759250507.855686   63138 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "W0000 00:00:1759250507.855687   63138 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n",
      "2025-09-30 23:41:47.893171: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "\n",
    "(x_train, _), (x_test, _) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "x_train = np.expand_dims(x_train, -1)\n",
    "x_test = np.expand_dims(x_test, -1)\n",
    "\n",
    "x_train_small = x_train[:1000]\n",
    "x_test_small = x_test[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78e4dbe4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E0000 00:00:1759250516.496396   63138 cuda_executor.cc:1132] failed to query device memory info: INTERNAL: CUDA error: : CUDA_ERROR_ASSERT: device-side assert triggered\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Failed to query available memory for GPU 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[23], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m             labels\u001b[38;5;241m.\u001b[39mappend(i)\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(rotated_images), np\u001b[38;5;241m.\u001b[39marray(labels)\n\u001b[0;32m---> 15\u001b[0m x_train_rot, y_train_rot \u001b[38;5;241m=\u001b[39m \u001b[43mrotate_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mangles\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m x_test_rot, y_test_rot \u001b[38;5;241m=\u001b[39m rotate_images(x_test_small, angles)\n",
      "Cell \u001b[0;32mIn[23], line 9\u001b[0m, in \u001b[0;36mrotate_images\u001b[0;34m(images, angles)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m img \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, angle \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(angles):\n\u001b[0;32m----> 9\u001b[0m         rotated \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrot90\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mangle\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m90\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     10\u001b[0m         rotated_images\u001b[38;5;241m.\u001b[39mappend(rotated\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     11\u001b[0m         labels\u001b[38;5;241m.\u001b[39mappend(i)\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.venv/lib/python3.10/site-packages/tensorflow/python/eager/context.py:726\u001b[0m, in \u001b[0;36mContext.ensure_initialized\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    722\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_ContextOptionsSetRunEagerOpAsFunction(opts, \u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m    723\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_ContextOptionsSetJitCompileRewrite(\n\u001b[1;32m    724\u001b[0m       opts, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile_rewrite\n\u001b[1;32m    725\u001b[0m   )\n\u001b[0;32m--> 726\u001b[0m   context_handle \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_NewContext(opts)\n\u001b[1;32m    727\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    728\u001b[0m   pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_DeleteContextOptions(opts)\n",
      "\u001b[0;31mUnknownError\u001b[0m: Failed to query available memory for GPU 0"
     ]
    }
   ],
   "source": [
    "angles = [0, 90, 180, 270]\n",
    "\n",
    "\n",
    "def rotate_images(images, angles):\n",
    "    rotated_images = []\n",
    "    labels = []\n",
    "    for img in images:\n",
    "        for i, angle in enumerate(angles):\n",
    "            rotated = tf.image.rot90(img, k=angle // 90)\n",
    "            rotated_images.append(rotated.numpy())\n",
    "            labels.append(i)\n",
    "    return np.array(rotated_images), np.array(labels)\n",
    "\n",
    "\n",
    "x_train_rot, y_train_rot = rotate_images(x_train_small, angles)\n",
    "x_test_rot, y_test_rot = rotate_images(x_test_small, angles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b072f7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential([\n",
    "    layers.Input(shape=(28, 28, 1)),\n",
    "    layers.Conv2D(32, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Conv2D(64, 3, activation='relu'),\n",
    "    layers.MaxPooling2D(),\n",
    "    layers.Flatten(),\n",
    "    layers.Dense(128, activation='relu'),\n",
    "    layers.Dense(len(angles), activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3d9f4df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1759241760.430980   45413 service.cc:152] XLA service 0x7fdd14018180 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1759241760.431138   45413 service.cc:160]   StreamExecutor device (0): NVIDIA GeForce RTX 3050 Ti Laptop GPU, Compute Capability 8.6\n",
      "2025-09-30 21:16:00.574485: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "I0000 00:00:1759241760.947974   45413 cuda_dnn.cc:529] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m20/63\u001b[0m \u001b[32m━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.4551 - loss: 1.1852"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1759241768.060809   45413 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m57/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━\u001b[0m \u001b[1m0s\u001b[0m 5ms/step - accuracy: 0.6150 - loss: 0.9197"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 21:16:08.665770: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_250', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 62ms/step - accuracy: 0.6325 - loss: 0.8869 - val_accuracy: 0.9212 - val_loss: 0.2818\n",
      "Epoch 2/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9178 - loss: 0.2502 - val_accuracy: 0.9425 - val_loss: 0.1826\n",
      "Epoch 3/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9596 - loss: 0.1308 - val_accuracy: 0.9575 - val_loss: 0.1190\n",
      "Epoch 4/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.9665 - loss: 0.0956 - val_accuracy: 0.9237 - val_loss: 0.2064\n",
      "Epoch 5/5\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.9683 - loss: 0.0946 - val_accuracy: 0.9625 - val_loss: 0.0947\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fddc07b9720>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train_rot, y_train_rot, epochs=5, batch_size=64,\n",
    "          validation_data=(x_test_rot, y_test_rot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59fe8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m25/25\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "predictions = model.predict(x_test_rot)\n",
    "\n",
    "num_examples = 5\n",
    "indices = np.random.choice(len(x_test_rot), num_examples, replace=False)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_test_rot[idx].squeeze()\n",
    "    true_label = y_test_rot[idx]\n",
    "    pred_label = np.argmax(predictions[idx])\n",
    "\n",
    "    plt.subplot(1, num_examples, i + 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"True: {angles[true_label]}°\\nPred: {angles[pred_label]}°\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd5d2aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train_labeled, y_train_labeled), (x_test_labeled,\n",
    "                                     y_test_labeled) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "x_train_labeled = x_train_labeled.astype('float32') / 255.\n",
    "x_test_labeled = x_test_labeled.astype('float32') / 255.\n",
    "x_train_labeled = np.expand_dims(x_train_labeled, -1)\n",
    "x_test_labeled = np.expand_dims(x_test_labeled, -1)\n",
    "\n",
    "x_train_fine = x_train_labeled[:1000]\n",
    "y_train_fine = y_train_labeled[:1000]\n",
    "x_test_fine = x_test_labeled[:200]\n",
    "y_test_fine = y_test_labeled[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3d8aad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-09-30 21:16:48.887005: I external/local_xla/xla/stream_executor/cuda/subprocess_compilation.cc:346] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_186', 4 bytes spill stores, 4 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 384ms/step - accuracy: 0.1885 - loss: 3.5476 - val_accuracy: 0.5800 - val_loss: 1.3281\n",
      "Epoch 2/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6996 - loss: 1.0810 - val_accuracy: 0.7600 - val_loss: 0.7975\n",
      "Epoch 3/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8425 - loss: 0.5973 - val_accuracy: 0.8250 - val_loss: 0.6033\n",
      "Epoch 4/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.8699 - loss: 0.4930 - val_accuracy: 0.8700 - val_loss: 0.4629\n",
      "Epoch 5/5\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9119 - loss: 0.3799 - val_accuracy: 0.8850 - val_loss: 0.3965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7fddb255e2c0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for layer in model.layers[:-2]:\n",
    "    layer.trainable = False\n",
    "\n",
    "model.pop()\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train_fine, y_train_fine, epochs=5, batch_size=64,\n",
    "          validation_data=(x_test_fine, y_test_fine))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32d33435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = model.predict(x_test_fine)\n",
    "\n",
    "indices = np.random.choice(len(x_test_fine), 5, replace=False)\n",
    "\n",
    "for i, idx in enumerate(indices):\n",
    "    img = x_test_fine[idx].squeeze()\n",
    "    true_label = y_test_fine[idx]\n",
    "    pred_label = np.argmax(predictions[idx])\n",
    "\n",
    "    plt.subplot(1, 5, i + 1)\n",
    "    plt.imshow(img, cmap='gray')\n",
    "    plt.title(f\"True: {true_label}\\nPred: {pred_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa81b2a",
   "metadata": {},
   "source": [
    "# Yeu cau 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cbd594",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "def rotate_images(images, angles):\n",
    "    rotated_images = []\n",
    "    labels = []\n",
    "    for img in images:\n",
    "        for i, angle in enumerate(angles):\n",
    "            rotated = torch.rot90(img, k=angle // 90, dims=[1, 2])\n",
    "            rotated_images.append(rotated)\n",
    "            labels.append(i)\n",
    "    return torch.stack(rotated_images), torch.tensor(labels)\n",
    "\n",
    "\n",
    "\n",
    " # image net transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "import os\n",
    "class HoaVNDatasetRotate(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data, self.label = self.load_images(root_path, angels=[0, 90, 180, 270])\n",
    "    \n",
    "    \n",
    "    def load_images(self, root_path, angels):\n",
    "        imgs_path = []\n",
    "        angel_label = []\n",
    "        for label in os.listdir(root_path):\n",
    "            label_path = os.path.join(root_path, label)\n",
    "            for img in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, img)\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                \n",
    "                for i, angle in enumerate(angels):\n",
    "                    rotated = img.rotate(angle)  # still PIL image\n",
    "                    imgs_path.append(rotated)\n",
    "                    angel_label.append(i)\n",
    "\n",
    "        return imgs_path, angel_label\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img =  self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c01ec6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = HoaVNDatasetRotate(root_path=\"/home/anhkhoa/ComputerVisionPlus/data/HoaVietNam/train\", transform=transform)\n",
    "test_dataset = HoaVNDatasetRotate(root_path=\"/home/anhkhoa/ComputerVisionPlus/data/HoaVietNam/test\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f1f69ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)   # (224,224,1) -> (222,222,32)\n",
    "        self.pool1 = nn.MaxPool2d(2, 2)                # (222,222,32) -> (111,111,32)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)  # (111,111,32) -> (109,109,64)\n",
    "        self.pool2 = nn.MaxPool2d(2, 2)                # (109,109,64) -> (54,54,64)\n",
    "        \n",
    "        self.flatten_dim = 64 * 54 * 54\n",
    "        self.fc1 = nn.Linear(self.flatten_dim, 128)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))   # Conv2D + ReLU\n",
    "        x = self.pool1(x)           # MaxPool\n",
    "        x = F.relu(self.conv2(x))   # Conv2D + ReLU\n",
    "        x = self.pool2(x)           # MaxPool\n",
    "        x = x.view(x.size(0), -1)   # Flatten\n",
    "        x = F.relu(self.fc1(x))     # Dense + ReLU\n",
    "        x = self.fc2(x)             # Dense (no softmax here)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63a2d91",
   "metadata": {},
   "source": [
    "# Pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8219b5a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  7.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Training Loss: 1.5700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Testing Loss: 1.1195\n",
      "Epoch 1/20, Test Accuracy: 54.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  9.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Training Loss: 1.0376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Testing Loss: 0.8585\n",
      "Epoch 2/20, Test Accuracy: 62.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  9.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Training Loss: 0.8672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Testing Loss: 0.7781\n",
      "Epoch 3/20, Test Accuracy: 64.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Training Loss: 0.7200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Testing Loss: 0.7780\n",
      "Epoch 4/20, Test Accuracy: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  9.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Training Loss: 0.6041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Testing Loss: 0.7850\n",
      "Epoch 5/20, Test Accuracy: 63.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Training Loss: 0.4707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Testing Loss: 0.8573\n",
      "Epoch 6/20, Test Accuracy: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  9.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Training Loss: 0.3795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Testing Loss: 0.7086\n",
      "Epoch 7/20, Test Accuracy: 67.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  7.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Training Loss: 0.2873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Testing Loss: 0.7702\n",
      "Epoch 8/20, Test Accuracy: 67.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Training Loss: 0.2388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Testing Loss: 0.7482\n",
      "Epoch 9/20, Test Accuracy: 65.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Training Loss: 0.1683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Testing Loss: 0.7755\n",
      "Epoch 10/20, Test Accuracy: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:01<00:00, 16.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Training Loss: 0.1050\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Testing Loss: 0.7955\n",
      "Epoch 11/20, Test Accuracy: 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Training Loss: 0.0760\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Testing Loss: 1.0915\n",
      "Epoch 12/20, Test Accuracy: 62.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Training Loss: 0.0953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Testing Loss: 0.9556\n",
      "Epoch 13/20, Test Accuracy: 63.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Training Loss: 0.0600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Testing Loss: 0.8428\n",
      "Epoch 14/20, Test Accuracy: 63.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  9.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Training Loss: 0.0336\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Testing Loss: 0.9323\n",
      "Epoch 15/20, Test Accuracy: 63.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Training Loss: 0.0244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Testing Loss: 0.9549\n",
      "Epoch 16/20, Test Accuracy: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Training Loss: 0.0181\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Testing Loss: 0.9549\n",
      "Epoch 17/20, Test Accuracy: 64.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Training Loss: 0.0119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Testing Loss: 0.9907\n",
      "Epoch 18/20, Test Accuracy: 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  8.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Training Loss: 0.0126\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 10.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Testing Loss: 1.0332\n",
      "Epoch 19/20, Test Accuracy: 65.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 19/19 [00:02<00:00,  9.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Training Loss: 0.0074\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing: 100%|██████████| 7/7 [00:00<00:00, 11.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Testing Loss: 1.0045\n",
      "Epoch 20/20, Test Accuracy: 64.50%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "epochs = 20\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleCNN(num_classes=4).to(device)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0003)\n",
    "\n",
    "\n",
    "for i in range(epochs):\n",
    "    avg_loss = 0.0\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader, desc = 'Training'):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        avg_loss += loss.item() \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    avg_loss /= len(train_loader)\n",
    "    print(f\"Epoch {i+1}/{epochs}, Training Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    avg_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc = 'Testing'):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            avg_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    avg_loss /= len(test_loader)\n",
    "    print(f\"Epoch {i+1}/{epochs}, Testing Loss: {avg_loss:.4f}\")\n",
    "\n",
    "    print(f\"Epoch {i+1}/{epochs}, Test Accuracy: {100 * correct / total:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d7869d",
   "metadata": {},
   "source": [
    "# Fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f72578f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "\n",
    "def rotate_images(images, angles):\n",
    "    rotated_images = []\n",
    "    labels = []\n",
    "    for img in images:\n",
    "        for i, angle in enumerate(angles):\n",
    "            rotated = torch.rot90(img, k=angle // 90, dims=[1, 2])\n",
    "            rotated_images.append(rotated)\n",
    "            labels.append(i)\n",
    "    return torch.stack(rotated_images), torch.tensor(labels)\n",
    "\n",
    "\n",
    "\n",
    " # image net transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "import os\n",
    "class HoaVNDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, root_path, transform=None):\n",
    "        self.transform = transform\n",
    "        self.data, self.label = self.load_images(root_path, angels=[0, 90, 180, 270])\n",
    "    \n",
    "    \n",
    "    def convert_label(self, label):\n",
    "        label_dict = {\n",
    "            'Cuc' : 0,\n",
    "            'Dao' : 1,\n",
    "            'Lan' : 2,\n",
    "            'Mai' : 3,\n",
    "            'Tho' : 4\n",
    "        }\n",
    "        return label_dict[label]\n",
    "    def load_images(self, root_path, angels):\n",
    "        imgs_path = []\n",
    "        angel_label = []\n",
    "        for label in os.listdir(root_path):\n",
    "            label_path = os.path.join(root_path, label)\n",
    "            for img in os.listdir(label_path):\n",
    "                img_path = os.path.join(label_path, img)\n",
    "                img = Image.open(img_path).convert(\"RGB\")\n",
    "                \n",
    "                imgs_path.append(img)\n",
    "                angel_label.append(self.convert_label(label))\n",
    "\n",
    "        return imgs_path, angel_label\n",
    "\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        img =  self.data[idx]\n",
    "        label = self.label[idx]\n",
    "        if self.transform:\n",
    "            img = self.transform(img)\n",
    "        return img, label\n",
    "\n",
    "train_dataset = HoaVNDataset(root_path=\"/home/anhkhoa/ComputerVisionPlus/data/HoaVietNam/train\", transform=transform)\n",
    "test_dataset = HoaVNDataset(root_path=\"/home/anhkhoa/ComputerVisionPlus/data/HoaVietNam/test\", transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "08b1f31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training:   0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  7.22it/s]\n",
      "Epoch 1/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 11.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20, Test Accuracy: 18.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.09it/s]\n",
      "Epoch 2/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20, Test Accuracy: 24.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.63it/s]\n",
      "Epoch 3/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 11.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20, Test Accuracy: 20.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.91it/s]\n",
      "Epoch 4/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 11.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20, Test Accuracy: 30.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.44it/s]\n",
      "Epoch 5/20 - Testing: 100%|██████████| 2/2 [00:00<00:00,  9.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20, Test Accuracy: 22.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  8.62it/s]\n",
      "Epoch 6/20 - Testing: 100%|██████████| 2/2 [00:00<00:00,  9.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20, Test Accuracy: 22.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.47it/s]\n",
      "Epoch 7/20 - Testing: 100%|██████████| 2/2 [00:00<00:00,  8.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20, Test Accuracy: 16.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.68it/s]\n",
      "Epoch 8/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20, Test Accuracy: 18.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.71it/s]\n",
      "Epoch 9/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20, Test Accuracy: 24.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.92it/s]\n",
      "Epoch 10/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/20, Test Accuracy: 24.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.16it/s]\n",
      "Epoch 11/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/20, Test Accuracy: 22.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.33it/s]\n",
      "Epoch 12/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/20, Test Accuracy: 28.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.82it/s]\n",
      "Epoch 13/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/20, Test Accuracy: 28.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.58it/s]\n",
      "Epoch 14/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/20, Test Accuracy: 32.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.20it/s]\n",
      "Epoch 15/20 - Testing: 100%|██████████| 2/2 [00:00<00:00,  9.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/20, Test Accuracy: 34.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.61it/s]\n",
      "Epoch 16/20 - Testing: 100%|██████████| 2/2 [00:00<00:00,  8.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/20, Test Accuracy: 40.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.11it/s]\n",
      "Epoch 17/20 - Testing: 100%|██████████| 2/2 [00:00<00:00,  8.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20, Test Accuracy: 52.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.43it/s]\n",
      "Epoch 18/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20, Test Accuracy: 44.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19/20 - Training: 100%|██████████| 5/5 [00:00<00:00, 10.49it/s]\n",
      "Epoch 19/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 11.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/20, Test Accuracy: 46.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20/20 - Training: 100%|██████████| 5/5 [00:00<00:00,  9.54it/s]\n",
      "Epoch 20/20 - Testing: 100%|██████████| 2/2 [00:00<00:00, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/20, Test Accuracy: 44.00%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Freeze toàn bộ\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Chỉ train layer cuối\n",
    "model.fc2 = nn.Linear(128, 5).to(device)\n",
    "for param in model.fc2.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.fc2.parameters(), lr=0.001)\n",
    "\n",
    "# ---------------------------\n",
    "# Training loop\n",
    "# ---------------------------\n",
    "epochs = 20\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    for images, labels in tqdm(train_loader, desc=f\"Epoch {epoch+1}/{epochs} - Training\"):\n",
    "        images, labels = images.to(device), labels.long().to(device)  # ép long\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    correct, total = 0, 0\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(test_loader, desc=f\"Epoch {epoch+1}/{epochs} - Testing\"):\n",
    "            images, labels = images.to(device), labels.long().to(device)\n",
    "            outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Test Accuracy: {100 * correct / total:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
